{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c88a275",
   "metadata": {},
   "source": [
    "# Image feature extraction\n",
    "\n",
    "Read and modify this notebook if you want to perform you own image feature extraction. Recall that **this is purely facultative**; you will not be penalized in any way if you chose not to do it, and it is also perfectly possible to obtain the maximum amount of points for the project using the default embeddings.\n",
    "\n",
    "Make sure to install the necessary packages before running the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb2208",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d3e7be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T14:10:14.286185789Z",
     "start_time": "2023-12-17T14:10:12.771932432Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "# Ignore all warning messages\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2541b",
   "metadata": {},
   "source": [
    "### A convolutional neural network model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5aa6a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T14:10:15.944130146Z",
     "start_time": "2023-12-17T14:10:15.928318227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a custom dataset class that inherits from the PyTorch Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    # Constructor for the dataset\n",
    "    def __init__(self, images, images_directory, target=None, transform=None):\n",
    "        # Initialize the dataset with the provided data and transformation options\n",
    "        self.images = images #List of image filenames\n",
    "        self.images_directory = images_directory # Directory where images are located\n",
    "        self.target = target # Optional list of target labels\n",
    "        \n",
    "        # If no data transformation is provided, create a default transformation\n",
    "        if transform is None:\n",
    "            transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "                                            transforms.ToTensor(), # Convert the image to a PyTorch tensor\n",
    "                                            transforms.Normalize(mean=[0.5], std=[0.5]) # Normalize the image data \n",
    "                                           ])\n",
    "            \n",
    "        self.transform = transform # Store the data transformation for later use\n",
    "\n",
    "    # Define the length of the dataset (number of data samples)\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    # Retrieve a specific data sample by its index\n",
    "    def __getitem__(self, idx):\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(self.images_directory, self.images[idx])\n",
    "        # Open the image using the PIL library\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Apply the data transformation if it exists\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # If target labels are provided, return both the image and the corresponding label esle return only the image\n",
    "        if self.target is not None:\n",
    "            target = self.target[idx]\n",
    "            return image, target\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        \n",
    "# Define a custom CNN class (in this class, we define the network architecture)  \n",
    "class SimpleCNN(nn.Module):\n",
    "    \n",
    "    # Constructor for the CNN \n",
    "    def __init__(self, n_features):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Define the layers of the CNN\n",
    "        # First convolutional layer with 1 input channel, 8 output channels, 3x3 kernel, and padding\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)\n",
    "        # First max-pooling layer with 2x2 kernel\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Second convolutional layer with 8 input channels, 8 output channels, 3x3 kernel, and padding\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1)\n",
    "        # Second max-pooling layer with 2x2 kernel\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layer with input size 8*7*7 and output size n_features\n",
    "        self.fc1 = nn.Linear(8*7*7, n_features)\n",
    "        # Fully connected layer with input size n_features and output size 1\n",
    "        self.fc2 = nn.Linear(n_features, 1) \n",
    "    \n",
    "    # Define the forward pass of the model\n",
    "    def forward(self, x):\n",
    "        # Apply the two first convolutional layers with max-pooling and ReLU activation functions\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        # Reshape the data for the fully connected layers\n",
    "        x = x.view(-1, 8*7*7)\n",
    "        # Pass the data through the first fully connected layer (and extract features)\n",
    "        extracted_features = self.fc1(x)\n",
    "        # Pass the extracted features through the second fully connected layer to get the final output\n",
    "        out = self.fc2(extracted_features)\n",
    "        # return output and extracted features\n",
    "        return out, extracted_features\n",
    "\n",
    "\n",
    "# Define a custom CNN model class (in this class, we define how to train the model)\n",
    "class MyCNN(object):\n",
    "    \n",
    "    # Constructor for the custom CNN model\n",
    "    def __init__(self, n_features= 8, n_epochs=25, batch_size=20, learning_rate=0.0005):\n",
    "        self.n_features = n_features\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    # Method to train the custom CNN model\n",
    "    def fit(self, images, y, data_dir):\n",
    "        \n",
    "        # Train and validation data split\n",
    "        split_ratio = 0.75\n",
    "        split_index = int(len(images) * split_ratio)\n",
    "        images_train = images[:split_index]\n",
    "        y_train = y[:split_index]\n",
    "        images_val= images[split_index:]\n",
    "        y_val = y[split_index:]\n",
    "\n",
    "        # Datasets\n",
    "        train_dataset = CustomDataset(images_train, data_dir, y_train)\n",
    "        val_dataset = CustomDataset(images_val, data_dir, y_val)\n",
    "\n",
    "        # Data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        # Create an instance of the SimpleCNN model\n",
    "        self.model = SimpleCNN(n_features=self.n_features)\n",
    "\n",
    "         # Define loss function and optimizer\n",
    "        criterion = nn.MSELoss(reduction='mean')\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            # Set the model in training mode\n",
    "            self.model.train()\n",
    "            # Initialize running loss\n",
    "            running_loss = 0\n",
    "            # Iterate over batches of training data\n",
    "            for i, data in enumerate(train_loader):\n",
    "                inputs, labels = data\n",
    "                \n",
    "                # Forward pass: Calculate model predictions and compute the loss\n",
    "                outputs, _ = self.model(inputs)\n",
    "                loss = criterion(outputs.squeeze(),labels.float())\n",
    "                \n",
    "                # Backpropagation: Zero the gradients, calculate gradients, and update the model's parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Keep track of the running loss for this epoch\n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "            \n",
    "            # Calculate the average training loss for this epoch\n",
    "            train_loss = np.sqrt(running_loss/(i+1))\n",
    "\n",
    "            # Model evaluation on the validation set\n",
    "            # Set the model in evaluation mode\n",
    "            self.model.eval()\n",
    "            # Initialize running loss\n",
    "            running_loss = 0\n",
    "            # Iterate over batches of validation data\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, labels = data\n",
    "                \n",
    "                # Forward pass: Calculate model predictions (no gradient calculation)\n",
    "                with torch.no_grad():\n",
    "                    outputs, _ = self.model(inputs)\n",
    "                    loss = criterion(outputs.squeeze(), labels.float())\n",
    "                    running_loss += loss.item()\n",
    "            \n",
    "            # Calculate the average validation loss for this epoch\n",
    "            val_loss = np.sqrt(running_loss/(i+1))\n",
    "            \n",
    "            # Print the training and validation loss every 5 epochs\n",
    "            if (epoch+1)%5 == 0:\n",
    "                print(\"Epoch: {epoch:2d} | Train loss: {train:5.3f} | Val loss: {val:5.3f}\".format(epoch=epoch+1,\n",
    "                                                                                                   train=train_loss,\n",
    "                                                                                                   val=val_loss))\n",
    "    # Method to make predictions with trained SimpleCNN model            \n",
    "    def predict(self, images, data_dir):\n",
    "        \n",
    "        # Create a dataset from the input images and data directory\n",
    "        dataset = CustomDataset(images, data_dir)\n",
    "        # Create a data loader with a batch size equal to the number of input images\n",
    "        loader = DataLoader(dataset, batch_size=len(images), shuffle=False)\n",
    "        \n",
    "        # Initialize an array to store predicted values\n",
    "        y_pred = np.zeros(len(images))\n",
    "        \n",
    "        # Set the model to evaluation mode (to disable features like dropout if needed)\n",
    "        self.model.eval()\n",
    "        # Make predictions on the input images without gradient calculation\n",
    "        with torch.no_grad():\n",
    "            for inputs in loader:\n",
    "                y_pred, _ = self.model(inputs)\n",
    "        \n",
    "        # Convert the predictions to a NumPy array and reshape it\n",
    "        return y_pred.numpy().reshape(-1)\n",
    "    \n",
    "    \n",
    "    # Method to extract features from input images with trained SimpleCNN model  \n",
    "    def extract_features(self, images, data_dir):\n",
    "        \n",
    "        # Create a dataset from the input images and data directory\n",
    "        dataset = CustomDataset(images, data_dir)\n",
    "        # Create a data loader with a batch size equal to the number of input images\n",
    "        loader = DataLoader(dataset, batch_size=len(images), shuffle=False)\n",
    "        \n",
    "        # Set the model to evaluation mode (to disable features like dropout)\n",
    "        self.model.eval()\n",
    "        # Extract features from the input images without gradient calculation\n",
    "        with torch.no_grad():\n",
    "            for inputs in loader:\n",
    "                _, features = self.model(inputs)\n",
    "        \n",
    "        # Convert the extracted features to a NumPy array\n",
    "        return features.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9b6fa",
   "metadata": {},
   "source": [
    "### Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba216fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T14:11:27.485870651Z",
     "start_time": "2023-12-17T14:11:24.909358100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 | Train loss: 0.095 | Val loss: 0.119\n",
      "Epoch: 10 | Train loss: 0.090 | Val loss: 0.113\n",
      "Epoch: 15 | Train loss: 0.086 | Val loss: 0.117\n",
      "Epoch: 20 | Train loss: 0.084 | Val loss: 0.104\n",
      "-----------------------------------------------\n",
      "RMSE on test set - MyCNN : 0.075\n"
     ]
    }
   ],
   "source": [
    "# Load Xtab1 and retrieve paths to images\n",
    "images1 = pd.read_csv(\"data/Xtab1.csv\")[\"img_filename\"]\n",
    "\n",
    "# Load targets\n",
    "Y1 = pd.read_csv(\"data/Y1.csv\", header=None, names=['risk'])\n",
    "\n",
    "# Concatenate for easier train/test separation\n",
    "df = pd.concat([images1,Y1], axis=1)\n",
    "\n",
    "# Train/test split (this is just an example, you should use your train/test split)\n",
    "df_train = df.sample(frac=0.8)\n",
    "df_test = df.drop(df_train.index)\n",
    "images_train = df_train[\"img_filename\"].values\n",
    "y_train = df_train[\"risk\"].values\n",
    "images_test = df_test[\"img_filename\"].values\n",
    "y_test = df_test[\"risk\"].values\n",
    "\n",
    "# Define the number of features to extract \n",
    "n_features=8\n",
    "\n",
    "# Create instance of cnn model\n",
    "cnn = MyCNN(n_features=n_features, batch_size=50, n_epochs=20, learning_rate=0.0005) \n",
    "\n",
    "# Fit cnn\n",
    "cnn.fit(images_train, y_train, 'data/Img1')\n",
    "\n",
    "# Performance evaluation\n",
    "y_pred = cnn.predict(images_test, 'data/Img1')\n",
    "rmse_cnn = np.sqrt(np.mean((y_pred-y_test)**2))\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"RMSE on test set - MyCNN : {rmse:5.3f}\".format(rmse=rmse_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f884793",
   "metadata": {},
   "source": [
    "### Extract features and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794a2cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T14:11:40.236737180Z",
     "start_time": "2023-12-17T14:11:40.086891787Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- new Ximg1 --- #\n",
    "# New file name for extracted feature (do no override Ximg1.csv in case you still need it)\n",
    "new_filename = \"MyXimg1.csv\"\n",
    "# Input images\n",
    "images = pd.read_csv(\"data/Xtab1.csv\")[\"img_filename\"].values\n",
    "# Etract features using trained model\n",
    "img_features = cnn.extract_features(images, \"data/Img1\")\n",
    "# Concatenate extracted features with corresponding image filenames\n",
    "Ximg1 = np.concatenate((img_features, images.reshape(-1,1)), axis=1)\n",
    "# Define new column names\n",
    "columns = [*[f\"h{i+1}\" for i in range(n_features)], \"img_filename\"]\n",
    "# Create pandas DataFrame\n",
    "Ximg1 = pd.DataFrame(Ximg1, columns=columns)\n",
    "# Define path to location of new file\n",
    "filepath = os.path.join(\"data\", \"staging\", new_filename)\n",
    "# Save pandas Dataframe in csv format\n",
    "Ximg1.to_csv(filepath, index=False)\n",
    "\n",
    "# --- new Ximg2 --- #\n",
    "# ... Do the same for images in Img2 (Use the same trained model as for producing Ximg1!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
